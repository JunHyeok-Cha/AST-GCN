# baseline_experiment.py (multi-task ë²„ì „)
#
# 1) X_samples.npy, Y_samples.npy ë¡œë¶€í„° DataLoader ìƒì„±
# 2) No-Graph Baseline ëª¨ë¸(MLP / LSTM) ì •ì˜
#    - ì¶œë ¥: TotalTraffic(t+1), Speed(t+1) ë™ì‹œ ì˜ˆì¸¡ (multi-task)
# 3) í•™ìŠµ ë£¨í”„ ì‹¤í–‰ ë° ì„±ëŠ¥ ì¶œë ¥
#
# âš  ì „ì œ: ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì´ë¯¸
#   - T_in, T_out
#   - X_samples.npy: (num_samples, N, T_in, F)
#   - Y_samples.npy: (num_samples, N, T_out, 2)
#     ì—¬ê¸°ì„œ ë§ˆì§€ë§‰ ì¶• 2ê°œ ì±„ë„ì€ [TotalTraffic, Speed]
#   ì´ ì €ì¥ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•œë‹¤.

from pathlib import Path
from typing import Tuple, List

import numpy as np
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, Subset


# =========================
# 0. ê³µí†µ ì„¤ì •
# =========================

data_dir = Path("/mnt/c/Source/python/AST-GCN/res")

# ğŸ”¥ multi-taskìš© X/Y íŒŒì¼ (TotalTraffic + Speed ë™ì‹œ ì˜ˆì¸¡)
X_path = data_dir / "X_samples.npy"
Y_path = data_dir / "Y_samples.npy"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)


# =========================
# 1. Dataset ì •ì˜
# =========================

class TrafficSamplesDataset(Dataset):
    """
    X_samples, Y_samples ë¥¼ ë˜í•‘í•˜ëŠ” Dataset.
    
    X: (S, N, T_in, F)
    Y: (S, N, T_out, 2)  â† [TotalTraffic, Speed]
    
    í•œ "ìƒ˜í”Œ"ì€ í•˜ë‚˜ì˜ "ì‹œê³„ì—´ ìœˆë„ìš° (T_in ì‹œê°„)" ì´ê³ ,
    ê·¸ ì•ˆì— Nê°œì˜ ë…¸ë“œê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆë‹¤.
    """
    def __init__(self, X: np.ndarray, Y: np.ndarray):
        assert X.shape[0] == Y.shape[0], "ìƒ˜í”Œ ê°œìˆ˜ ë¶ˆì¼ì¹˜"
        self.X = torch.from_numpy(X).float()  # (S, N, T_in, F)
        self.Y = torch.from_numpy(Y).float()  # (S, N, T_out, 2)

    def __len__(self) -> int:
        return self.X.shape[0]

    def __getitem__(self, idx: int):
        # ë°˜í™˜ í˜•íƒœ: (N, T_in, F), (N, T_out, 2)
        return self.X[idx], self.Y[idx]


def get_dataloaders(
    X_path: Path,
    Y_path: Path,
    batch_size: int = 4,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
    seed: int = 42,
) -> Tuple[DataLoader, DataLoader, DataLoader, dict]:
    """
    X_samples.npy, Y_samples.npy ë¡œë¶€í„°
    Train / Val / Test DataLoader ë¥¼ ìƒì„±í•œë‹¤.
    """

    X = np.load(X_path)  # (S, N, T_in, F)
    Y = np.load(Y_path)  # (S, N, T_out, 2)

    S, N, T_in, F = X.shape
    S2, N2, T_out, num_targets = Y.shape
    assert S == S2 and N == N2, "X, Yì˜ ìƒ˜í”Œ ê°œìˆ˜ / ë…¸ë“œ ìˆ˜ê°€ ë‹¤ë¦„"
    assert num_targets == 2, "Y ë§ˆì§€ë§‰ ì¶•ì€ 2 (TotalTraffic, Speed) ì´ì–´ì•¼ í•¨"

    print(f"[Data] X: {X.shape}, Y: {Y.shape}")
    print(f"[Data] N={N}, T_in={T_in}, F={F}, T_out={T_out}, num_targets={num_targets}")

    dataset = TrafficSamplesDataset(X, Y)

    # ---------- ì¸ë±ìŠ¤ ì…”í”Œ í›„ Train/Val/Test ë‚˜ëˆ„ê¸° ----------
    rng = np.random.RandomState(seed)
    indices = np.arange(S)
    rng.shuffle(indices)

    n_test = int(S * test_ratio)
    n_val = int(S * val_ratio)
    n_train = S - n_val - n_test

    train_idx = indices[:n_train]
    val_idx   = indices[n_train:n_train + n_val]
    test_idx  = indices[n_train + n_val:]

    print(f"[Split] train={len(train_idx)}, val={len(val_idx)}, test={len(test_idx)}")

    train_ds = Subset(dataset, train_idx)
    val_ds   = Subset(dataset, val_idx)
    test_ds  = Subset(dataset, test_idx)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)
    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)

    meta = dict(N=N, T_in=T_in, F=F, T_out=T_out, num_targets=num_targets)
    return train_loader, val_loader, test_loader, meta


# =========================
# 2. No-Graph Multi-task Baseline ëª¨ë¸ë“¤
# =========================

class MLPBaselineMultiTask(nn.Module):
    """
    ê·¸ë˜í”„ ì •ë³´ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” Multi-task Baseline (MLP).
    
    - ì…ë ¥: x (B, N, T_in, F)
    - ë‚´ë¶€: ê° ë…¸ë“œ ì‹œí€€ìŠ¤ (T_in * F) ë¥¼ ë²¡í„°ë¡œ í¼ì³ì„œ
            ê³µìœ  MLP ì— ë„£ëŠ”ë‹¤ (ë…¸ë“œë³„ ë…ë¦½ ì²˜ë¦¬, íŒŒë¼ë¯¸í„° ê³µìœ ).
    - ì¶œë ¥: y_hat (B, N, T_out, 2)
            â†’ [TotalTraffic(t+1), Speed(t+1)]
    """
    def __init__(
        self,
        T_in: int,
        F: int,
        T_out: int = 1,
        num_targets: int = 2,
        hidden_dims: List[int] = [64, 64],
        dropout: float = 0.1,
    ):
        super().__init__()
        self.T_in = T_in
        self.F = F
        self.T_out = T_out
        self.num_targets = num_targets

        in_dim = T_in * F
        layers = []
        prev_dim = in_dim

        for h_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, h_dim))
            layers.append(nn.ReLU())
            if dropout > 0:
                layers.append(nn.Dropout(dropout))
            prev_dim = h_dim

        # ì¶œë ¥ì¸µ: T_out * num_targets (ì˜ˆ: 1 * 2 = 2)
        out_dim = T_out * num_targets
        layers.append(nn.Linear(prev_dim, out_dim))

        self.mlp = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (B, N, T_in, F)
        return: (B, N, T_out, num_targets)
        """
        B, N, T_in, F = x.shape
        assert T_in == self.T_in and F == self.F

        # (B, N, T_in, F) -> (B * N, T_in * F)
        x_flat = x.view(B * N, T_in * F)

        # (B*N, T_out*num_targets)
        y_flat = self.mlp(x_flat)

        # (B, N, T_out, num_targets)
        y = y_flat.view(B, N, self.T_out, self.num_targets)
        return y


class LSTMBaselineMultiTask(nn.Module):
    """
    ê·¸ë˜í”„ ì •ë³´ë¥¼ ì „í˜€ ì“°ì§€ ì•ŠëŠ” Multi-task LSTM Baseline.
    
    - ì…ë ¥: x (B, N, T_in, F)
    - ë‚´ë¶€: (B * N, T_in, F) ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ í›„
            ê³µìœ  LSTM ì ìš© â†’ ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… hidden ì‚¬ìš©
    - ì¶œë ¥: y_hat (B, N, T_out, 2)
    """
    def __init__(
        self,
        F: int,
        hidden_size: int = 64,
        num_layers: int = 1,
        T_out: int = 1,
        num_targets: int = 2,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        super().__init__()
        self.F = F
        self.T_out = T_out
        self.num_targets = num_targets
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bidirectional = bidirectional

        self.lstm = nn.LSTM(
            input_size=F,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,  # ì…ë ¥ (B*N, T_in, F)
            dropout=dropout if num_layers > 1 else 0.0,
            bidirectional=bidirectional,
        )
        lstm_out_dim = hidden_size * (2 if bidirectional else 1)

        # ë§ˆì§€ë§‰ hidden â†’ T_out * num_targets ë¡œ ë§¤í•‘
        self.fc = nn.Linear(lstm_out_dim, T_out * num_targets)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (B, N, T_in, F)
        return: (B, N, T_out, num_targets)
        """
        B, N, T_in, F = x.shape
        assert F == self.F

        # (B, N, T_in, F) -> (B*N, T_in, F)
        x_seq = x.view(B * N, T_in, F)

        out, (h_n, c_n) = self.lstm(x_seq)
        # out: (B*N, T_in, hidden)
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥ ì‚¬ìš©
        h_last = out[:, -1, :]  # (B*N, hidden*dir)

        y_flat = self.fc(h_last)  # (B*N, T_out*num_targets)
        y = y_flat.view(B, N, self.T_out, self.num_targets)
        return y


# =========================
# 3. í•™ìŠµ / í‰ê°€ ë£¨í”„
# =========================

def train_one_epoch(
    model: nn.Module,
    loader: DataLoader,
    optimizer: torch.optim.Optimizer,
    criterion: nn.Module,
) -> Tuple[float, float, float, float]:
    """
    í•œ epoch ë™ì•ˆ train_loader ì— ëŒ€í•´ í•™ìŠµí•˜ê³ ,
    í‰ê·  loss / MAE(all) / MAE(traffic) / MAE(speed) ë¥¼ ë°˜í™˜.
    """
    model.train()
    total_loss = 0.0
    total_mae_all = 0.0
    total_mae_traffic = 0.0
    total_mae_speed = 0.0
    total_count = 0

    for xb, yb in loader:
        # xb: (B, N, T_in, F)
        # yb: (B, N, T_out, 2)
        xb = xb.to(device)
        yb = yb.to(device)

        optimizer.zero_grad()

        y_hat = model(xb)  # (B, N, T_out, 2)
        loss = criterion(y_hat, yb)

        loss.backward()
        optimizer.step()

        B = xb.size(0)
        total_loss += loss.item() * B

        diff = (y_hat - yb).abs()  # (B, N, T_out, 2)
        mae_all = diff.mean().item()
        mae_traffic = diff[..., 0].mean().item()
        mae_speed   = diff[..., 1].mean().item()

        total_mae_all += mae_all * B
        total_mae_traffic += mae_traffic * B
        total_mae_speed   += mae_speed * B
        total_count += B

    avg_loss = total_loss / total_count
    avg_mae_all = total_mae_all / total_count
    avg_mae_traffic = total_mae_traffic / total_count
    avg_mae_speed = total_mae_speed / total_count
    return avg_loss, avg_mae_all, avg_mae_traffic, avg_mae_speed


@torch.no_grad()
def evaluate(
    model: nn.Module,
    loader: DataLoader,
    criterion: nn.Module,
) -> Tuple[float, float, float, float]:
    """
    Val/Test ìš© í‰ê°€ í•¨ìˆ˜.
    í‰ê·  loss / MAE(all) / MAE(traffic) / MAE(speed) ë°˜í™˜.
    """
    model.eval()
    total_loss = 0.0
    total_mae_all = 0.0
    total_mae_traffic = 0.0
    total_mae_speed = 0.0
    total_count = 0

    for xb, yb in loader:
        xb = xb.to(device)
        yb = yb.to(device)

        y_hat = model(xb)
        loss = criterion(y_hat, yb)

        B = xb.size(0)
        total_loss += loss.item() * B

        diff = (y_hat - yb).abs()
        mae_all = diff.mean().item()
        mae_traffic = diff[..., 0].mean().item()
        mae_speed   = diff[..., 1].mean().item()

        total_mae_all += mae_all * B
        total_mae_traffic += mae_traffic * B
        total_mae_speed   += mae_speed * B
        total_count += B

    avg_loss = total_loss / total_count
    avg_mae_all = total_mae_all / total_count
    avg_mae_traffic = total_mae_traffic / total_count
    avg_mae_speed = total_mae_speed / total_count
    return avg_loss, avg_mae_all, avg_mae_traffic, avg_mae_speed


# =========================
# 4. ë©”ì¸: MLP / LSTM ì¤‘ í•˜ë‚˜ ê³¨ë¼ì„œ í•™ìŠµ
# =========================

def main(model_type: str = "mlp"):
    # 1) DataLoader ì¤€ë¹„
    train_loader, val_loader, test_loader, meta = get_dataloaders(
        X_path, Y_path,
        batch_size=2,   # Nì´ ì»¤ì„œ batch_sizeëŠ” ì‘ê²Œ
        val_ratio=0.15,
        test_ratio=0.15,
        seed=42,
    )
    N = meta["N"]
    T_in = meta["T_in"]
    F = meta["F"]
    T_out = meta["T_out"]
    num_targets = meta["num_targets"]
    print("Meta:", meta)

    # 2) ëª¨ë¸ ì„ íƒ
    if model_type == "mlp":
        model = MLPBaselineMultiTask(
            T_in=T_in,
            F=F,
            T_out=T_out,
            num_targets=num_targets,
            hidden_dims=[64, 64],
            dropout=0.1,
        )
    elif model_type == "lstm":
        model = LSTMBaselineMultiTask(
            F=F,
            hidden_size=64,
            num_layers=1,
            T_out=T_out,
            num_targets=num_targets,
            dropout=0.0,
            bidirectional=False,
        )
    else:
        raise ValueError("model_type ì€ 'mlp' ë˜ëŠ” 'lstm' ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    model = model.to(device)
    print(model)

    # 3) í•™ìŠµ
    criterion = nn.MSELoss()  # ëª¨ë“  íƒ€ê¹ƒ(traffic, speed)ì— ëŒ€í•´ í‰ê·  MSE
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)

    num_epochs = 100
    best_val_loss = float("inf")
    best_state = None

    for epoch in range(1, num_epochs + 1):
        train_loss, train_mae_all, train_mae_tr, train_mae_sp = train_one_epoch(
            model, train_loader, optimizer, criterion
        )
        val_loss, val_mae_all, val_mae_tr, val_mae_sp = evaluate(
            model, val_loader, criterion
        )

        print(
            f"[Epoch {epoch:03d}] "
            f"Train Loss: {train_loss:.4f}, MAE(all): {train_mae_all:.4f}, "
            f"MAE(traffic): {train_mae_tr:.4f}, MAE(speed): {train_mae_sp:.4f} | "
            f"Val Loss: {val_loss:.4f}, MAE(all): {val_mae_all:.4f}, "
            f"MAE(traffic): {val_mae_tr:.4f}, MAE(speed): {val_mae_sp:.4f}"
        )

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_state = model.state_dict()

    # 4) best ëª¨ë¸ë¡œ Test í‰ê°€
    if best_state is not None:
        model.load_state_dict(best_state)

    test_loss, test_mae_all, test_mae_tr, test_mae_sp = evaluate(
        model, test_loader, criterion
    )
    print(
        f"[Test] Loss: {test_loss:.4f}, MAE(all): {test_mae_all:.4f}, "
        f"MAE(traffic): {test_mae_tr:.4f}, MAE(speed): {test_mae_sp:.4f}"
    )

    # 5) ëª¨ë¸ ì €ì¥
    save_path = data_dir / f"baseline_{model_type}_multitask_best.pth"
    torch.save(
        {
            "model_type": model_type,
            "state_dict": model.state_dict(),
            "meta": meta,
        },
        save_path,
    )
    print("Saved best model to:", save_path)


if __name__ == "__main__":
    # main(model_type="mlp")
    main(model_type="lstm")
